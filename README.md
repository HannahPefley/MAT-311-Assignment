# MAT-311-Assignment
Assignment submission/files for MAT 311 AI assignment.

This assignment (duplicating a provided notebook by using AP) was completed *using ChatGPT-4.O* as an assistant. The goal of this assignment was given as recreating a given notebook strictly by prompting an AI assistant to produce the proper code. This notebook (`ai_credit_card_fraud_detection_recreation.ipynb`) follows through the steps of evaluating given data about credit card transactions, cleaning up missing values, performing exploratory analysis through data descriptions and visualizations, constructing two models, and evaluating the performance of the models with various metrics. Through this process, various prompts were provided to ChatGPT-4.O (the prompts are included within the notebook) and the output response from the AI model was taken and inserted into the notebook. This essentially gives us a notebook where all code is generated by AI, however it is important to remember that it was guided by a human who was checking it for error, providing the proper prompts and adjustments to prompts, etc. to get it to where it needed to be to successfully recreate the original file. 

**Two Paragraph Reflection**
*Instructions: Have a 2-paragraph section in here where you reflect on AI assistance with
this assignment*

There are many benefits that AI (specifically ChatGPT-4.O in this case) brought to the construction of this notebook. It eliminated the need to figure out every single function, parameter, and all of the syntax necessary to do what I wanted. I could put the end goal (type of chart, apperance of output, etc.) and have pretty much an exact template for the general form, which could them be tweaked by changing some words here and there within the prompt if necessary. While AI has many benefits, it could be dangerous or irresponsible in the hands of people that have not learned proper data science techniques. Some might just put in an end goal without doing any initial processing or checking of the data, and achieve results that look nice, but are truly unhelpful. For example, someone that has a dataset that is missing many values, is poorly formatted, or is unbalanced could get a response that neglects to check for null values, lacks the background of the unbalancedness in choosing proper metrics of evaluation, or is unable to handle variables as they are formatted. If they just blindly ask AI to perform analysis, make models, or draw conclusions, one mistake or missed detail about the data or analysis steps can mean an error in any conclusions drawn, and someone without data science experience or knowledge may struggle to troubleshoot the errors, or even identify biased or incorrect conclusions in the first place.

Every time I recieved output from the AI, I ensured that I checked it for correctness against the original notebook. There were a few specific places where it seemed especially necessary. One place where I needed to verify the output provided by the AI for correctness without just blindly trusting it. After splitting the testing and training data, I soon realized that i had not specified the random seed to use during the split. So I quickly checked the code and saw that ChatGPT-4.O had actually used the same random seed (42) that was used in the original notebook. I knew to verify this when I realized I had forgotten to check, and then was surprised and happy to see that it had actually included that parameter successfully. Another example of an instance where I needed to verify the AI output for correctness was when the initial graphs were generated. Originally, for the confusion matrix heatmaps and bar charts, I noticed that my numbers were not quite aligning and that the charts were looking slightly different. After going back through the code, I realized that the code ChatGPT-4.O had produced was not splitting the data using `stratify=y` in the proper place, and thus there were different values in the different data sets. After tweaking the prompt to add that in, I obtained the correct graphs. Those two were just a few examples of different ways I needed to verify the AI output to ensure it was correct before accepting it as final. 
